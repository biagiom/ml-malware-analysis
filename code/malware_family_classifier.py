import naive_bayes_text as nb
from util import build_dataset
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
import seaborn as sns; sns.set()

dataset_path = "../drebin/feature_vectors/"
family_labels_path = "../drebin/sha256_family.csv"
feature_list = ['permission', 'call', 'api_call', 'intent']
eta = 1
types = ["bernoulli", "multinomial"]
mode = "skip_safe"
rseed = 10
num_samples = 4000

DEBUG = False
num_classes = 6
num_iter = 4

if __name__ == '__main__':

    nb_classifier = nb.NaiveBayesText(debug_mode=False, perc=2/3, rand_seed=rseed)

    dataset = build_dataset(dataset_path, family_labels_path, feature_list,
                            num_samples, eta, rseed, mode, True, False)

    # select the most numerous <num_classes> classes
    labels = {c: 0 for c in set([dataset[app]["target"] for app in dataset])}
    for l in labels:
        labels[l] = len([app for app in dataset if dataset[app]["target"] == l])

    if num_classes > len(labels):
        num_classes = len(labels)

    sel_classes = [c for c, num in sorted(labels.items(), key=lambda x: x[1], reverse=True)[:num_classes]]

    parsed_dataset = {}
    for app in dataset:
        if dataset[app]["target"] in sel_classes:
            parsed_dataset[app] = dataset[app]

    print("*** Malware Family Classification ***")

    print("Number of docs in the parsed dataset: {}".format(len(parsed_dataset)))

    avg_accuracy = {t: 0 for t in types}

    for n in range(num_iter):
        print("TEST #{}".format(n + 1))

        train_set, train_class, test_set, \
        test_class, classes = nb_classifier.split_dataset(parsed_dataset, random_split=True)
        print("Classes:")
        print(classes)

        for t in types:
            if t == "bernoulli":
                print("\nUsing the Naive Bayes classifier with Multi-variate Bernoulli distribution")
            else:
                print("\nUsing the Naive Bayes classifier with Multinomial distribution")

            nb_classifier.fit(train_set, train_class, classes, t)

            estimated_class = nb_classifier.classify(test_set, classes)

            if DEBUG is True:
                print("Estimated class labels:")
                print(estimated_class)
                print("Target (True) class labels:")
                print(test_class)

            accuracy, conf_matrix = nb_classifier.evaluate(estimated_class, test_class, classes)
            print("\nAccuracy: {:.3f}".format(accuracy))
            print("Confusion matrix:")
            print(conf_matrix)

            avg_accuracy[t] += accuracy

            target_names = list(classes.keys())
            plt.figure()
            if t == "bernoulli":
                plt.title("Confusion matrix - Bernoulli Naive Bayes")
            else:
                plt.title("Confusion matrix - Multinomial Naive Bayes")
            sns.heatmap(conf_matrix.T, square=True, annot=True, fmt='d', cbar=False,
                        xticklabels=target_names, yticklabels=target_names)
            plt.xlabel('true label')
            plt.ylabel('predicted label')
            plt.draw()
            plt.tight_layout()

            print("\nClassification report using Sklearn:")
            print(classification_report(test_class, estimated_class, target_names=target_names))
            print('{:-<60}'.format(""))

        plt.show()

    for mode in avg_accuracy:
        avg_accuracy[mode] /= num_iter

    print("Average accuracy over {} tests:".format(num_iter))
    print("Bernoulli Naive Bayes -> accuracy = {:.2f}".format(avg_accuracy["bernoulli"]))
    print("Multinomial Naive Bayes -> accuracy = {:.2f}".format(avg_accuracy["multinomial"]))